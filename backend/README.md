# ReNova - AI-Driven Waste Intelligence System

Complete backend implementation using **FastAPI + MongoDB + CLIP + Whisper + OpenAI**.

---

## ğŸ—ï¸ Architecture

```
User Input (Image/Voice/Text)
    â†“
Input Normalization (Hindi â†’ English)
    â†“
Vision Module (CLIP) â†’ Material Classification
    â†“
OSM Context â†’ Location, Recyclers, Roads
    â†“
Personal Context â†’ User History
    â†“
Time Context â†’ Hour, Day
    â†“
Fusion Layer â†’ Combined Embedding
    â†“
Dual-RAG â†’ Global + Personal Knowledge
    â†“
LLM Reasoning (English) â†’ Disposal Instructions
    â†“
Translation (English â†’ Hindi if needed)
    â†“
Token Generation + Impact Tracking
```

---

## ğŸ“‚ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ api/                    # API endpoints
â”‚   â”‚   â”œâ”€â”€ scan_routes.py      # POST /scan_image, /voice_input, /rag_query
â”‚   â”‚   â”œâ”€â”€ user_routes.py      # GET /user/{id}, /token_balance
â”‚   â”‚   â”œâ”€â”€ recycler_routes.py  # GET /recycler/items_pending, POST /recycler/submit
â”‚   â”‚   â”œâ”€â”€ marketplace_routes.py  # GET /recyclers_nearby, POST /schedule_pickup
â”‚   â”‚   â”œâ”€â”€ token_routes.py     # POST /user/redeem_token
â”‚   â”‚   â””â”€â”€ impact_routes.py    # GET /impact_stats
â”‚   â”œâ”€â”€ models/                 # Pydantic models
â”‚   â”‚   â”œâ”€â”€ user_models.py
â”‚   â”‚   â”œâ”€â”€ recycler_models.py
â”‚   â”‚   â”œâ”€â”€ scan_models.py
â”‚   â”‚   â”œâ”€â”€ token_models.py
â”‚   â”‚   â”œâ”€â”€ rag_models.py
â”‚   â”‚   â”œâ”€â”€ marketplace_models.py
â”‚   â”‚   â””â”€â”€ impact_models.py
â”‚   â”œâ”€â”€ services/               # Core services
â”‚   â”‚   â”œâ”€â”€ database.py         # MongoDB connection
â”‚   â”‚   â””â”€â”€ vector_db.py        # Milvus/FAISS
â”‚   â”œâ”€â”€ vision/                 # CLIP vision
â”‚   â”‚   â””â”€â”€ clip_service.py
â”‚   â”œâ”€â”€ voice/                  # Whisper ASR
â”‚   â”‚   â””â”€â”€ whisper_service.py
â”‚   â”œâ”€â”€ osm/                    # OpenStreetMap
â”‚   â”‚   â””â”€â”€ osm_service.py
â”‚   â”œâ”€â”€ fusion/                 # Embedding fusion
â”‚   â”‚   â””â”€â”€ fusion_service.py
â”‚   â”œâ”€â”€ rag/                    # RAG retrieval
â”‚   â”‚   â””â”€â”€ rag_service.py
â”‚   â”œâ”€â”€ utils/                  # LLM & fraud
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â””â”€â”€ fraud_service.py
â”‚   â”œâ”€â”€ marketplace/            # Recycler ranking
â”‚   â”‚   â””â”€â”€ marketplace_service.py
â”‚   â”œâ”€â”€ tokens/                 # Token system
â”‚   â”‚   â””â”€â”€ token_service.py
â”‚   â””â”€â”€ impact/                 # Impact calculation
â”‚       â””â”€â”€ impact_service.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.9+
- MongoDB (running on localhost:27017)
- OpenAI API Key

### 2. Installation

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your credentials
nano .env
```

Required environment variables:
```env
MONGODB_URL=mongodb://localhost:27017
OPENAI_API_KEY=sk-your-key-here
SECRET_KEY=your-secret-key-here
```

### 4. Run Server

```bash
# Start FastAPI server
python -m app.main

# Or with uvicorn directly
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Server will be available at: **http://localhost:8000**

---

## ğŸ“¡ API Endpoints

### User APIs

#### POST `/api/scan_image`
Complete scan pipeline with image.

**Form Data:**
- `user_id`: string
- `image`: file (jpeg/png)
- `latitude`: float
- `longitude`: float
- `query_text`: string (optional)
- `language`: string (en/hi)

**Response:**
```json
{
  "scan_id": "...",
  "material": "PET",
  "confidence": 0.95,
  "cleanliness_score": 85.0,
  "disposal_instruction": "...",
  "estimated_credits": 12,
  "environmental_impact": {
    "co2_saved_kg": 2.1,
    "water_saved_liters": 15.0,
    "landfill_saved_kg": 1.0
  }
}
```

#### POST `/api/voice_input`
Transcribe voice to text.

**Form Data:**
- `user_id`: string
- `audio`: file (wav/mp3/m4a)
- `language`: string (en/hi)

#### POST `/api/rag_query`
Query knowledge base without image.

#### GET `/api/token_balance?user_id=...`
Get user's wallet balance.

---

### Recycler APIs

#### GET `/api/recycler/items_pending?recycler_id=...`
Get pending scans for processing.

#### POST `/api/recycler/submit`
Submit weight and generate token.

**Form Data:**
- `recycler_id`: string
- `scan_id`: string
- `weight_kg`: float
- `material_override`: string (optional)

**Response:**
```json
{
  "success": true,
  "credits_awarded": 12,
  "token": {
    "token_id": "ABC123",
    "credits": 12,
    "expires_at": "2025-11-14T..."
  }
}
```

#### POST `/api/user/redeem_token`
User redeems token.

**Form Data:**
- `user_id`: string
- `token_id`: string

---

### Marketplace APIs

#### GET `/api/recyclers_nearby?lat=...&lon=...&material=...`
Get ranked recyclers.

#### POST `/api/schedule_pickup`
Schedule waste pickup.

---

### Impact APIs

#### GET `/api/impact_stats?user_id=...&period=all_time`
Get environmental impact statistics.

---

## ğŸ”§ Technology Stack

| Component | Technology |
|-----------|-----------|
| **Framework** | FastAPI |
| **Database** | MongoDB (Motor async driver) |
| **Vector DB** | FAISS / Milvus |
| **Vision** | CLIP (OpenAI) |
| **Voice** | Whisper (OpenAI) |
| **LLM** | GPT-4 (OpenAI) |
| **Translation** | GPT-3.5 (OpenAI) |
| **Geospatial** | OpenStreetMap (Nominatim, Overpass, OSRM) |
| **Image Hashing** | imagehash (perceptual hash) |

---

## ğŸ§® Formulas

### Credit Calculation
```
credits = base_rate(material) Ã— weight_kg Ã— (cleanliness_score / 100)
```

### Material Base Rates (credits/kg)
- PET: 12
- HDPE: 10
- Paper: 5
- Glass: 4
- Metal: 15
- E-Waste: 20

### Environmental Impact
- **COâ‚‚ Saved**: `material_factor Ã— weight_kg` (kg)
- **Water Saved**: `material_factor Ã— weight_kg` (liters)
- **Landfill Saved**: `weight_kg` (kg)

### Recycler Scoring
```
score = 0.3Ã—distance + 0.25Ã—material_accept + 0.15Ã—capacity + 
        0.1Ã—price + 0.1Ã—road_access + 0.1Ã—catchment_zone
```

---

## ğŸ“Š MongoDB Collections

| Collection | Purpose |
|-----------|---------|
| `users` | User profiles |
| `recyclers` | Recycler/collection centers |
| `wallets` | User credit wallets |
| `pending_items` | Scans awaiting processing |
| `completed_scans` | Processed scans |
| `tokens` | Credit vouchers |
| `token_redemptions` | Redemption logs |
| `recycler_submissions` | Recycler submissions |
| `rag_global` | Global knowledge base |
| `rag_personal` | User-specific documents |
| `user_behavior` | User behavior analytics |
| `pickups` | Scheduled pickups |
| `impact_stats` | Environmental impact stats |
| `heatmap_tiles` | Geospatial heatmap |
| `fraud_checks` | Fraud detection logs |

---

## ğŸ” Fraud Prevention

The system implements multiple fraud checks:

1. **Image Hashing**: Detect duplicate images
2. **CLIP Similarity**: Detect internet/stock images
3. **GPS Mismatch**: Flag unusual locations
4. **Weight Sanity**: Validate realistic weights
5. **Token Expiry**: 24-hour expiration
6. **User-Token Binding**: Tokens belong to specific users

---

## ğŸŒ Geospatial Features

- **Reverse Geocoding**: Lat/lon â†’ Address
- **Nearby Search**: Find recyclers within radius
- **Route Calculation**: Distance and duration via OSRM
- **Road Assessment**: Accessibility scoring
- **Heatmap Tiles**: Slippy map tiles (zoom/x/y)

---

## ğŸ§ª Testing

```bash
# Install test dependencies
pip install pytest pytest-asyncio httpx

# Run tests
pytest
```

Example API test:
```bash
curl -X POST http://localhost:8000/api/scan_image \
  -F "user_id=12345" \
  -F "image=@waste_bottle.jpg" \
  -F "latitude=12.9716" \
  -F "longitude=77.5946" \
  -F "language=hi"
```

---

## ğŸ“ Notes

### Language Support
- All processing happens in **English**
- Hindi translation occurs only at final output
- Input normalization: Hindi â†’ English â†’ Processing â†’ Hindi

### Vector Embeddings
- CLIP produces 768-dimensional embeddings
- Location features: 128-dim
- User history: 256-dim
- Time context: 64-dim
- All fused into 768-dim vector

### MongoDB Geospatial
- Uses GeoJSON format: `{type: "Point", coordinates: [lon, lat]}`
- 2dsphere indexes for fast queries
- $near queries for proximity search

---

## ğŸš¨ Important Points

1. **No SQL/PostgreSQL** - Only MongoDB
2. **No TypeScript/Node.js** - Only Python
3. **English Processing** - LLM works in English only
4. **Hindi Translation** - Only at final step
5. **Exact Pipeline** - Follows specification exactly

---

## ğŸ“ Support

For issues or questions, check the logs:
```bash
tail -f app.log
```

---

## ğŸ‰ Complete Implementation

This implementation includes **ALL** specified components:
- âœ… Input normalization (voice, image, text)
- âœ… Vision module (CLIP)
- âœ… OSM integration
- âœ… Personal & time context
- âœ… Fusion layer
- âœ… Dual-RAG retrieval
- âœ… LLM reasoning (English)
- âœ… Hindi translation
- âœ… Token system with fraud prevention
- âœ… Impact engine
- âœ… Marketplace & routing
- âœ… All required API endpoints
- âœ… Complete MongoDB schema

**No deviations. Production-ready.**
